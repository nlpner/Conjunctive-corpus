6月2日晚间，英伟达创始人兼首席执行官黄仁勋登台演讲，透露了不少关键信息。据他介绍，使用NVIDIANIM将AI模型部署在云、数据中心或工作站上的开发者，<cand>可</cand>将模型部署时间从以前的数周缩短至几分钟。和硕、劳氏公司、西门子等客户均在使用。
<cand>此外</cand>，被英伟达寄予厚望的新一代AI芯片与超级计算平台Blackwell芯片已开始投产，预计将在2025年推出BlackwellUltraAI芯片。
6月2日晚间，一身皮衣的英伟达创始人黄仁勋又在舞台上摆弄起了自家产品，重磅介绍了NVIDIANIM，一种推理微服务，<cand>可</cand>通过经优化的容器形式提供模型，旨在助力各种规模企业部署AI服务。
<cand>不过</cand>，严格来说，NVIDIANIM并非新品，最早露面是在今年3月。英伟达在6月2日晚间宣布，全球2800万开发者皆可下载NVIDIANIM，将AI模型部署在云、数据中心或工作站上，构建Copilot（一种AI助理）、ChatGPT聊天机器人等生成式AI应用。下月起，NVIDIA开发者计划的会员可免费使用NIM，在其选择的基础设施上进行研究、开发和测试。
根据英伟达的说法，新的生成式AI应用正变得越来越复杂，通常需要使用具有不同功能的多个模型来生成文本，<cand>如</cand>图像、视频、语音等。<cand>而</cand>NVIDIANIM提供了一种简单、标准化的方式——将生成式AI添加到应用中，<cand>可</cand>使模型部署时间从以前的数周缩短至几分钟。
黄仁勋<cand>还</cand>透露，包括Cadence、Cloudera、Cohesity、DataStax、NetApp、ScaleAI和新思科技等近200家技术合作伙伴正在将NIM集成到他们的平台中，<cand>以</cand>加快生成式AI部署。“每个企业都希望在其运营中融入生成式AI，<cand>但</cand>并非每个企业都拥有专门的AI研究团队。NVIDIANIM可被集成到任意平台中，任何地方的开发者都可以访问，<cand>并且</cand>可以在任意环境中运行。”黄仁勋称。
《每日经济新闻》记者了解到，NIM是预先构建的，目前有近40个模型可作为NIM的端点供开发者体验；开发人员可从开源社区平台HuggingFace访问适用于MetaLlama3模型的NVIDIANIM微服务，使用HuggingFace推理端点访问和运行Llama3NIM。
值得注意的是，英伟达<cand>还</cand>透露了一批大客户的使用情况，<cand>如</cand>电子制造商Foxconn正在使用NIM开发针对特定领域的大语言模型（LLM），用于智能制造、智慧城市和智能电动汽车；和硕正在将NIM用于一个当地的混合专家（MoE）模型；劳氏公司正在用NVIDIANIM推理微服务来提升员工和客户的体验；西门子正在将其运营技术与NIM微服务整合，用于车间AI工作负载；<cand>还</cand>有数十家医疗保健公司正在部署NIM，<cand>为</cand>包括手术规划、数字助理、药物发现和临床试验优化等在内的应用领域的生成性AI推理提供支持。
除了上述产品，黄仁勋还在演讲中透露，英伟达Blackwell芯片已开始投产，<cand>并</cand>将在2025年推出BlackwellUltraAI芯片。
今年5月，黄仁勋在财报电话会上称，预计今年Blackwell架构芯片将为公司带来大量收入。英伟达对Blackwell芯片寄予厚望，<cand>还</cand>是与市场强劲需求有关。从最新披露的财报数据来看，2025财年第一财季，英伟达实现营收260亿美元，较上年同期增长262%。<cand>其中</cand>，数据中心业务营收226亿美元，与上年同期相比增长427%，是业绩收入的“大头”。
据英伟达首席财务官科莱特•克雷斯解读，数据中心业务的增长源自Hopper架构GPU（例如H100）出货量的增加；该季度的重要亮点之一就是Meta宣布推出Lama3开源大模型，使用了近2.4万块H100GPU。
除了披露芯片量产进度，英伟达此次<cand>还</cand>推出了一系列采用NVIDIABlackwell架构的系统。
据悉，这些系统搭载了GraceCPU以及NVIDIA网络和基础设施，用于助力企业建立AI工厂和数据中心。<cand>其中</cand>，NVIDIAMGX模块化参考设计平台加入了对NVIDIABlackwell产品的支持，包括专为主流大语言模型推理、检索增强生成和数据处理提供卓越性能打造的NVIDIAGB200NVL2平台。
英伟达强调，GB200NVL2适合用于数据分析等新兴领域，借助NVLink—C2C互连技术带来的带宽内存性能及Blackwell架构中专有的解压缩引擎，较使用X86CPU时的数据处理速度可最多提速到18倍，能效提高8倍。“新一轮工业革命已经开始，众多企业和地区正在与NVIDIA合作推动价值万亿美元的传统数据中心向加速计算转型，<cand>并</cand>建造一种新型数据中心AI工厂来生产新的商品，人工智能。”黄仁勋称。
英伟达方面表示，目前已有超过25家合作伙伴的90多套已发布或正在开发中的系统使用了MGX参考架构，开发成本较之前最多降低了四分之三，开发时间缩短到六个月，较之前减少了三分之二。<cand>另外</cand>，英伟达<cand>还</cand>透露，比亚迪电子、西门子、泰瑞达和Alphabet旗下公司Intrinsic等全球十多家机器人企业正在将NVIDIAIsaac加速库、基于物理学的仿真和AI模型集成到其软件框架和机器人模型中，<cand>以</cand>此提高工厂、仓库和配送中心的工作效率。
