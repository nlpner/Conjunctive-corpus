Transformer很强，Transformer很好，<cand>但</cand>Transformer在处理时序数据时存在一定的局限性。<cand>如</cand>计算复杂度高、对长序列数据处理不够高效等问题。
<cand>而</cand>在数据驱动的时代，时序预测成为许多领域中不可或缺的一部分。
于是乎，蚂蚁同清华联合推出一种纯MLP架构的模型TimeMixer，在时序预测上的性能和效能两方面全面超越了Transformer模型。
他们结合对时序趋势周期特性的分解以及多尺度混合的设计模式，<a>不仅</a>在长短程预测性能上大幅提升，<a>而且</a>基于纯MLP架构实现了接近于线性模型的极高效率。
来康康是如何做到的？
TimeMixer模型采用了一个多尺度混合架构，旨在解决时间序列预测中的复杂时间变化问题。
该模型主要采用全MLP（多层感知机）架构，由过去可分解混合PastDecomposableMixing(PDM)和未来多预测器混合FutureMultipredictorMixing(FMM)两大块构成，能够有效利用多尺度序列信息。
<cand>其中</cand>PDM模块，负责提取过去的信息并将不同尺度上的季节性和趋势组分分别混合。
PDM以季节和趋势混合为动力，将详细的季节信息由细到粗逐步聚合，<cand>并</cand>利用较粗尺度的先验知识深入挖掘宏观趋势信息，最终实现过去信息提取中的多尺度混合。
FMM则是多个预测器的集合，<cand>其中</cand>不同的预测器基于不同尺度的过去信息，<cand>使</cand>FMM能够集成混合多尺度序列的互补预测功能。
<cand>为了</cand>验证TimeMixer的性能，团队在包含长程预测，短程预测，多元时序预测以及具有时空图结构的18组基准数据集上进行了实验，包括电力负荷预测、气象数据预测和股票价格预测等。
预测精度：在所有测试的数据集上，TimeMixer均表现出更高的预测精度。<cand>以</cand>电力负荷预测为例，TimeMixer相比于Transformer模型，平均绝对误差（MAE）降低了约15%，均方根误差（RMSE）降低了约12%。
计算效率：得益于MLP结构的高效计算特性，TimeMixer在训练时间和推理时间上均显著优于Transformer模型。实验数据显示，在相同硬件条件下，TimeMixer的训练时间减少了约30%，推理时间减少了约25%。
模型可解释性：通过引入PastDecomposableMixing和FutureMultipredictorMixing技术，TimeMixer能够更好地解释不同时间尺度上的信息贡献，<cand>使得</cand>模型的决策过程更加透明和易于理解。
泛化能力：在多个不同类型的数据集上进行测试，TimeMixer均表现出良好的泛化能力，能够适应不同的数据分布和特征。这表明TimeMixer在实际应用中具有广泛的适用性。
长程预测：<cand>为了</cand>确保模型比较的公平性，使用标准化参数进行实验，调整输入长度、批量大小和训练周期。<a>此外</a>，鉴于各种研究的结果通常源于超参数优化，该研究<a>还</a>包括了综合参数搜索的结果。
消融实验：<cand>为了</cand>验证TimeMixer每个组件的有效性，我们在所有18个实验基准上对Past-Decomposable-Mishing和Future-Multipredictor-Mishing模块中的每种可能的设计进行了详细的消融研究。
模型效率：团队将训练阶段的运行内存和时间与最新最先进的模型进行比较，<cand>其中</cand>TimeMixer在GPU内存和运行时间方面，对于各种系列长度（范围从192到3072）始终表现出良好的效率，<cand>此外</cand>还具有长期和短期预测任务一致的最先进性能。
值得注意的是，TimeMixer作为深度模型，在效率方面表现出接近全线性模型的结果。这<cand>使得</cand>TimeMixer在各种需要高模型效率的场景中大有前途。
好了，TimeMixer为时序预测领域带来了新的思路，<cand>也</cand>展示了纯MLP结构在复杂任务中的潜力。
未来，随着更多优化技术和应用场景的引入，相信TimeMixer将进一步推动时序预测技术的发展，<cand>为</cand>各行业带来更大的价值。
本项目获得了蚂蚁集团智能引擎事业部旗下AI创新研发部门NextEvo支持。
蚂蚁集团NextEvo-优化智能团队负责蚂蚁运筹优化、时序预测以及预测优化相结合的智能决策等技术方向，团队工作涵盖算法技术、平台服务和解决方案的研发。
