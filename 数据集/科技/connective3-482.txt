一群现任和前任OpenAI员工周二发表了一封公开信，表达对人工智能行业快速发展的担忧，<cand>并</cand>指出其缺乏监督，<cand>也</cand>缺乏对那些希望发声者的举报人保护。
公开信中写道：“人工智能公司有很强的财务动机来避免有效的监督，我们认为公司治理的定制结构不足以改变这一点。”
预计生成式人工智能市场在10年内收入将超过1万亿美元。OpenAI、谷歌、微软、Meta及其他公司正在主宰生成式人工智能军备竞赛，<cand>因为</cand>似乎每个公司都急于拥有自己的人工智能驱动的聊天机器人和代理，<cand>以</cand>避免被竞争对手甩在后面。
OpenAI的现任和前任员工在公开信中写道，人工智能公司拥有“大量非公开信息”，包括他们的技术可以做什么，他们采取的安全措施的程度以及技术对不同类型伤害的风险水平。
“我们也理解这些技术带来的严重风险，”他们写道，<cand>并</cand>补充说，这些公司“目前只有微弱的义务与政府分享其中一些信息，<cand>而</cand>没有与民间社会分享。我们认为不能依靠他们自愿分享它。”
这封信<cand>还</cand>详细说明了现任和前任员工对人工智能行业举报人保护不足的担忧，<cand>并</cand>指出，<cand>如果</cand>没有有效的政府监督，员工在追究公司责任方面处于相对独特的地位。
公开信称：“宽泛的保密协议阻止我们表达我们的担忧，除非是那些可能未能解决这些问题的公司，”签署者写道。“普通的举报人保护是不够的，<cand>因为</cand>它们侧重于非法活动，<cand>而</cand>我们担心的许多风险尚未受到监管。”
