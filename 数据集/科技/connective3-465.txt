IT之家6月12日消息，<cand>还</cand>记得谷歌的人工智能搜索结果告诉用户往披萨里加胶水的那件事吗？<cand>当时</cand>国外网红凯蒂・诺托普洛斯(KatieNotopoulos)还真做了一个“胶水披萨”并吃掉了它，这件事在网上引起了热议。<cand>不过</cand>现在出现了一个问题：谷歌的人工智能正在学习这些网络热梗。
诚然，人们很少会查询“往披萨里加多少胶水”这种问题，<cand>但</cand>考虑到最近“胶水披萨”的热度，<cand>也</cand>并非完全不可能。安全研究员科林・麦克米伦(ColinMcMillen)发现，<cand>如果</cand>你询问谷歌应该往披萨里加多少胶水，<cand>并</cand>不会得到正确的答案——那就是绝对不要加胶水。相反，谷歌会引用凯蒂的恶搞文章，建议用户加八分之一杯胶水，这显然是很危险的。TheVerge通过搜索验证了这一点。
TheVerge称，这<cand>意味着</cand>网友向谷歌报告其人工智能出错，实际上是在“训练”它继续犯错。
另一个问题是，<cand>由于</cand>采用了人工智能技术，谷歌现在似乎无法回答有关其自身产品的问题了。TheVerge的编辑询问了如何在隐身模式下截取Chrome浏览器的截图，谷歌的人工智能给出了两个答案都错了。<cand>其中</cand>一个建议在普通模式的Chrome标签页中截取截图，另一个答案则坚称在Chrome隐身模式下根本无法截屏。
IT之家注意到，谷歌首席执行官桑达尔・皮查伊此前在接受采访时承认，这些“AI摘要”功能产生的“幻觉”是大型语言模型（LLM）的“固有缺陷”，<cand>而</cand>大型语言模型正是“AI摘要”功能的核心技术。皮查伊表示，这个问题目前尚无解决方案（isstillanunsolvedproblem）。
